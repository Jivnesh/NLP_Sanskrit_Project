{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import pickle\n",
    "#run this code on a server, laptop will not be able to handle it. loop of 11,000*8,00,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"Extracted.db\")\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_sql(\"SELECT * FROM Sample\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metapath2 = pd.read_sql(\"SELECT * FROM metapath2\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metapath3 = pd.read_sql(\"SELECT * FROM metapath3\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metapath4 = pd.read_sql(\"SELECT * FROM metapath4\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('CNGG_count.pickle', 'rb') as handle:\n",
    "     CNGG_count = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('CNG_count.pickle', 'rb') as handle:\n",
    "     CNG_count = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Word_count.pickle', 'rb') as handle:\n",
    "     Word_count = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Lemma_count.pickle', 'rb') as handle:\n",
    "     Lemma_count = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()   # start with x's keys and values\n",
    "    z.update(y)    # modifies z with y's keys and values & returns None\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "innerdict = merge_two_dicts(CNG_count, CNGG_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "features = defaultdict(list)\n",
    "for mp2i,mp2r in metapath2.iterrows():\n",
    "    node1 = mp2r['node1']\n",
    "    node2 = mp2r['node2']\n",
    "    \n",
    "    vector = []\n",
    "    \n",
    "    for i,r in sample.iterrows():\n",
    "        den = 0\n",
    "        \n",
    "        if node1 == 'Lemma':\n",
    "            value1 = r['Entity_1'].split(\"_\")[0]\n",
    "            den = Lemma_count[value1]\n",
    "        elif node1 == 'CNG':\n",
    "            value1 = r['Entity_1'].split(\"_\")[1]\n",
    "            den = CNG_count[int(value1)]\n",
    "        else:\n",
    "            value1 = r['Entity_1']\n",
    "            den = Word_count[value1]\n",
    "            \n",
    "        \n",
    "        if node2 == 'Lemma':\n",
    "            value2 = r['Entity_2'].split(\"_\")[0]\n",
    "        elif node2 == 'CNG':\n",
    "            value2 = r['Entity_2'].split(\"_\")[1]\n",
    "        else:\n",
    "            value2 = r['Entity_2']        \n",
    "        \n",
    "        if den == 0:\n",
    "            prob12 = 0\n",
    "        else:\n",
    "            temp = pd.read_sql(\"SELECT Weight FROM Graph WHERE Entity_1 = %s AND Entity_2 = %s\" %(value1, value2))\n",
    "            prob12 = temp.Weight[0]/den\n",
    "            \n",
    "            prob = prob12\n",
    "        \n",
    "        vector.append(prob)\n",
    "    \n",
    "    features[node1+'|'+node2] = vector\n",
    "#Important: Word|Word column vector is our label vector ! for Mutual Information Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for mp3i,mp3r in metapath3.iterrows():\n",
    "    node1 = mp3r['node1']\n",
    "    node2 = mp3r['node2']\n",
    "    node3 = mp3r['node3']\n",
    "    vector = []\n",
    "    \n",
    "    for i,r in sample.iterrows():\n",
    "        den1 = 0\n",
    "        den2 = 0\n",
    "        \n",
    "        if node1 == 'Lemma':\n",
    "            value1 = r['Entity_1'].split(\"_\")[0]\n",
    "            den1 = Lemma_count[value1]\n",
    "        elif node1 == 'CNG':\n",
    "            value1 = r['Entity_1'].split(\"_\")[1]\n",
    "            den1 = CNG_count[int(value1)]\n",
    "        else:\n",
    "            value1 = r['Entity_1']\n",
    "            den1 = Word_count[value1]\n",
    "        \n",
    "        value2 = node2\n",
    "        \n",
    "        if node3 == 'Lemma':\n",
    "            value3 = r['Entity_2'].split(\"_\")[0]\n",
    "        elif node3 == 'CNG':\n",
    "            value3 = r['Entity_2'].split(\"_\")[1]\n",
    "        else:\n",
    "            value3 = r['Entity_2']\n",
    "            \n",
    "        den2 = innerdict[node2]\n",
    "        \n",
    "        if den1 == 0:\n",
    "            prob12 = 0\n",
    "        else:\n",
    "            temp = pd.read_sql(\"SELECT Weight FROM Graph WHERE Entity_1 = %s AND Entity_2 = %s\" %(value1, value2))\n",
    "            prob12 = temp.Weight[0]/den1\n",
    "        \n",
    "        if den2 == 0:\n",
    "            prob23 = 0\n",
    "        else:\n",
    "            temp = pd.read_sql(\"SELECT Weight FROM Graph WHERE Entity_1 = %s AND Entity_2 = %s\" %(value2, value3))\n",
    "            prob23 = temp.Weight[0]/den2\n",
    "            \n",
    "        prob = prob12*prob23\n",
    "\n",
    "        vector.append(prob)\n",
    "    \n",
    "    features[node1 + '|' + node2 + '|'+ node3]  = vector\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for mp4i,mp4r in metapath4.iterrows():\n",
    "    node1 = mp4r['node1']\n",
    "    node2 = mp4r['node2']\n",
    "    node3 = mp4r['node3']\n",
    "    node4 = mp4r['node4']\n",
    "    vector = []\n",
    "    \n",
    "    for i,r in sample.iterrows():\n",
    "        den1 = 0\n",
    "        den2 = 0\n",
    "        den3 = 0\n",
    "        \n",
    "        if node1 == 'Lemma':\n",
    "            value1 = r['Entity_1'].split(\"_\")[0]\n",
    "            den1 = Lemma_count[value1]\n",
    "        elif node1 == 'CNG':\n",
    "            value1 = r['Entity_1'].split(\"_\")[1]\n",
    "            den1 = CNG_count[int(value1)]\n",
    "        else:\n",
    "            value1 = r['Entity_1']\n",
    "            den1 = Word_count[value1]\n",
    "        \n",
    "        value2 = node2\n",
    "        \n",
    "        value3 = node3\n",
    "        \n",
    "        if node4 == 'Lemma':\n",
    "            value4 = r['Entity_2'].split(\"_\")[0]\n",
    "        elif node4 == 'CNG':\n",
    "            value4 = r['Entity_2'].split(\"_\")[1]\n",
    "        else:\n",
    "            value4 = r['Entity_2']\n",
    "            \n",
    "        den2 = innerdict[node2]\n",
    "        den3 = innerdict[node3]\n",
    "        \n",
    "        if den1 == 0:\n",
    "            prob12 = 0\n",
    "        else:\n",
    "            temp = pd.read_sql(\"SELECT Weight FROM Graph WHERE Entity_1 = %s AND Entity_2 = %s\" %(value1, value2))\n",
    "            prob12 = temp.Weight[0]/den1\n",
    "        \n",
    "        if den2 == 0:\n",
    "            prob23 = 0\n",
    "        else:\n",
    "            temp = pd.read_sql(\"SELECT Weight FROM Graph WHERE Entity_1 = %s AND Entity_2 = %s\" %(value2, value3))\n",
    "            prob23 = temp.Weight[0]/den2\n",
    "            \n",
    "        if den3 == 0:\n",
    "            prob34 = 0\n",
    "        else:\n",
    "            temp = pd.read_sql(\"SELECT Weight FROM Graph WHERE Entity_1 = %s AND Entity_2 = %s\" %(value3, value4))\n",
    "            prob34 = temp.Weight[0]/den3\n",
    "            \n",
    "        \n",
    "        prob = prob12*prob23*prob34\n",
    "\n",
    "        vector.append(prob)\n",
    "    \n",
    "    features[node1 + '|' + node2 + '|'+ node3 + '|' +node4]  = vector\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn1 = sqlite3.connect(\"Features.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(features, index = [i for i in range(110001)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe.to_sql(\"FeaturesRaw\", conn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()\n",
    "conn1.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
