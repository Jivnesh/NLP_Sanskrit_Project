{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "#run this code on a server, laptop will not be able to handle it. loop of 11,000*8,00,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"Extracted.db\")\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_sql(\"SELECT * FROM Sample\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = pd.read_sql(\"SELECT * FROM Graph\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metapath2 = pd.read_sql(\"SELECT * FROM metapath2\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metapath3 = pd.read_sql(\"SELECT * FROM metapath3\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metapath4 = pd.read_sql(\"SELECT * FROM metapath4\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('CNGG_count.pickle', 'rb') as handle:\n",
    "    CNGG_count = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('CNG_count.pickle', 'rb') as handle:\n",
    "    CNG_count = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Word_count.pickle', 'rb') as handle:\n",
    "    Word_count = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Lemma_count.pickle', 'rb') as handle:\n",
    "    Lemma_count = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()   # start with x's keys and values\n",
    "    z.update(y)    # modifies z with y's keys and values & returns None\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "innerdict = merge_two_dicts(CNG_count, CNGG_count)\n",
    "#we merge them for easier selection in the future\n",
    "#as denominators in metapath3,4 are either count of CNG or CNG_Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = defaultdict(list)\n",
    "global features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use threading for the following operations, on a server\n",
    "\n",
    "def mp2(metapath2, sample):\n",
    "\n",
    "    for mp2i,mp2r in metapath2.iterrows():\n",
    "        #iterating through all metapaths of size 2\n",
    "        node1 = mp2r['node1']\n",
    "        node2 = mp2r['node2']\n",
    "        #since it is a metapath of size 2 we have only 2 nodes\n",
    "\n",
    "        vector = []\n",
    "\n",
    "        for i,r in sample.iterrows():\n",
    "            #iterating through 11,000 samples we selected\n",
    "            den = 0\n",
    "            #initializing denominator of bigram probability to 0\n",
    "            \n",
    "            #checking to see what type of External nodes are there in the metapath\n",
    "            #assigning den as per type of node\n",
    "            \n",
    "            if node1 == 'Lemma':\n",
    "                value1 = r['Entity_1'].split(\"_\")[0]\n",
    "                den = Lemma_count[value1]\n",
    "            elif node1 == 'CNG':\n",
    "                value1 = r['Entity_1'].split(\"_\")[1]\n",
    "                den = CNG_count[int(value1)]\n",
    "            else:\n",
    "                value1 = r['Entity_1']\n",
    "                den = Word_count[value1]\n",
    "\n",
    "\n",
    "            if node2 == 'Lemma':\n",
    "                value2 = r['Entity_2'].split(\"_\")[0]\n",
    "            elif node2 == 'CNG':\n",
    "                value2 = r['Entity_2'].split(\"_\")[1]\n",
    "            else:\n",
    "                value2 = r['Entity_2']        \n",
    "\n",
    "            if den == 0:\n",
    "                #this is okay as we will be considering metapaths with maximum unique values \n",
    "                prob12 = 0\n",
    "            else:\n",
    "                \n",
    "                temp = graph.loc[ (graph['Entity_1'] == value1) & (graph['Entity_2'] == value2)] \n",
    "                #temp is used to get numeratr of bigram probabily from Graph\n",
    "#               temp = pd.read_sql(\"SELECT Weight FROM Graph WHERE Entity_1 = '%s' AND Entity_2 = '%s' \" %(value1, value2))\n",
    "                prob12 = temp.Weight[0]/den\n",
    "\n",
    "                prob = prob12\n",
    "\n",
    "            vector.append(prob)\n",
    "\n",
    "        features[node1+'|'+node2] = vector\n",
    "#Important: Word|Word column vector is our label vector ! for Mutual Information Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def mp3(metapath3, sample):\n",
    "    \n",
    "    for mp3i,mp3r in metapath3.iterrows():\n",
    "        #iterating through all metapaths of size 3\n",
    "        node1 = mp3r['node1']\n",
    "        node2 = mp3r['node2']\n",
    "        node3 = mp3r['node3']\n",
    "        #since it is a metapath of size 3 we have only 3 nodes\n",
    "        vector = []\n",
    "\n",
    "        for i,r in sample.iterrows():\n",
    "            den1 = 0\n",
    "            den2 = 0\n",
    "\n",
    "            if node1 == 'Lemma':\n",
    "                value1 = r['Entity_1'].split(\"_\")[0]\n",
    "                den1 = Lemma_count[value1]\n",
    "            elif node1 == 'CNG':\n",
    "                value1 = r['Entity_1'].split(\"_\")[1]\n",
    "                den1 = CNG_count[int(value1)]\n",
    "            else:\n",
    "                value1 = r['Entity_1']\n",
    "                den1 = Word_count[value1]\n",
    "\n",
    "            value2 = node2\n",
    "\n",
    "            if node3 == 'Lemma':\n",
    "                value3 = r['Entity_2'].split(\"_\")[0]\n",
    "            elif node3 == 'CNG':\n",
    "                value3 = r['Entity_2'].split(\"_\")[1]\n",
    "            else:\n",
    "                value3 = r['Entity_2']\n",
    "\n",
    "            den2 = innerdict[node2]\n",
    "            #selecting from innerdict as it has counts of both CNG and CNG_Groups\n",
    "\n",
    "            if den1 == 0:\n",
    "                prob12 = 0\n",
    "            else:\n",
    "                temp = graph.loc[ (graph['Entity_1'] == value1) & (graph['Entity_2'] == value2)] \n",
    "#               temp = pd.read_sql(\"SELECT Weight FROM Graph WHERE Entity_1 = %s AND Entity_2 = %s\" %(value1, value2))\n",
    "                prob12 = temp.Weight[0]/den1\n",
    "\n",
    "            if den2 == 0:\n",
    "                prob23 = 0\n",
    "                \n",
    "            else:\n",
    "                temp = graph.loc[ (graph['Entity_1'] == value2) & (graph['Entity_2'] == value3)] \n",
    "#               temp = pd.read_sql(\"SELECT Weight FROM Graph WHERE Entity_1 = %s AND Entity_2 = %s\" %(value2, value3))\n",
    "                prob23 = temp.Weight[0]/den2\n",
    "\n",
    "            prob = prob12*prob23\n",
    "\n",
    "            vector.append(prob)\n",
    "\n",
    "        features[node1 + '|' + node2 + '|'+ node3]  = vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mp4(metapath4, sample):\n",
    "    \n",
    "\n",
    "    for mp4i,mp4r in metapath4.iterrows():\n",
    "        #iterating through all metapaths of size 4\n",
    "        node1 = mp4r['node1']\n",
    "        node2 = mp4r['node2']\n",
    "        node3 = mp4r['node3']\n",
    "        node4 = mp4r['node4']\n",
    "        \n",
    "        #since it is a metapath of size 4 we have only 4 nodes\n",
    "        vector = []\n",
    "\n",
    "        for i,r in sample.iterrows():\n",
    "            den1 = 0\n",
    "            den2 = 0\n",
    "            den3 = 0\n",
    "\n",
    "            if node1 == 'Lemma':\n",
    "                value1 = r['Entity_1'].split(\"_\")[0]\n",
    "                den1 = Lemma_count[value1]\n",
    "            elif node1 == 'CNG':\n",
    "                value1 = r['Entity_1'].split(\"_\")[1]\n",
    "                den1 = CNG_count[int(value1)]\n",
    "            else:\n",
    "                value1 = r['Entity_1']\n",
    "                den1 = Word_count[value1]\n",
    "\n",
    "            value2 = node2\n",
    "\n",
    "            value3 = node3\n",
    "\n",
    "            if node4 == 'Lemma':\n",
    "                value4 = r['Entity_2'].split(\"_\")[0]\n",
    "            elif node4 == 'CNG':\n",
    "                value4 = r['Entity_2'].split(\"_\")[1]\n",
    "            else:\n",
    "                value4 = r['Entity_2']\n",
    "\n",
    "            den2 = innerdict[node2]\n",
    "            den3 = innerdict[node3]\n",
    "\n",
    "            if den1 == 0:\n",
    "                prob12 = 0\n",
    "            else:\n",
    "                temp = graph.loc[ (graph['Entity_1'] == value1) & (graph['Entity_2'] == value2)] \n",
    "#               temp = pd.read_sql(\"SELECT Weight FROM Graph WHERE Entity_1 = %s AND Entity_2 = %s\" %(value1, value2))\n",
    "                prob12 = temp.Weight[0]/den1\n",
    "\n",
    "            if den2 == 0:\n",
    "                prob23 = 0\n",
    "            else:\n",
    "                temp = graph.loc[ (graph['Entity_1'] == value2) & (graph['Entity_2'] == value3)] \n",
    "#               temp = pd.read_sql(\"SELECT Weight FROM Graph WHERE Entity_1 = %s AND Entity_2 = %s\" %(value2, value3))\n",
    "                prob23 = temp.Weight[0]/den2\n",
    "\n",
    "            if den3 == 0:\n",
    "                prob34 = 0\n",
    "            else:\n",
    "                temp = graph.loc[ (graph['Entity_1'] == value3) & (graph['Entity_2'] == value4)] \n",
    "#               temp = pd.read_sql(\"SELECT Weight FROM Graph WHERE Entity_1 = %s AND Entity_2 = %s\" %(value3, value4))\n",
    "                prob34 = temp.Weight[0]/den3\n",
    "\n",
    "\n",
    "            prob = prob12*prob23*prob34\n",
    "\n",
    "            vector.append(prob)\n",
    "\n",
    "        features[node1 + '|' + node2 + '|'+ node3 + '|' +node4]  = vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Threading begins here\n",
    "#Calculate Length of Metapahts so that we can slpit them for threading \n",
    "lenmp2 = len(metapath2.node1)\n",
    "lenmp3 = len(metapath3.node1)\n",
    "lenmp4 = len(metapath4.node1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Running a total of 20 threads , mp2 : 1 , mp3: 5, mp4 : 14 threads respectivly \n",
    "\n",
    "step3 = int(lenmp3/5)\n",
    "step4 = int(lenmp4/14)\n",
    "ind3 = []\n",
    "z =0\n",
    "for i in range(4):\n",
    "    ind3.append([z, z+step3])\n",
    "    z = z+step3\n",
    "ind3.append([z, lenmp3-1])\n",
    "\n",
    "ind4=[]\n",
    "z =0\n",
    "for i in range(13):\n",
    "    ind4.append([z, z+step4])\n",
    "    z = z+step4\n",
    "ind4.append([z, lenmp4-1])\n",
    "\n",
    "    \n",
    "t1 = threading.Thread(target=mp2, args=(metapath2, sample))\n",
    "\n",
    "t2 = threading.Thread(target=mp3, args=(metapath3[ind3[0][0]:ind3[0][1], :], sample))\n",
    "t3 = threading.Thread(target=mp3, args=(metapath3[ind3[1][0]:ind3[1][1], :], sample))\n",
    "t4 = threading.Thread(target=mp3, args=(metapath3[ind3[2][0]:ind3[2][1], :], sample))\n",
    "t5 = threading.Thread(target=mp3, args=(metapath3[ind3[3][0]:ind3[3][1], :], sample))\n",
    "t6 = threading.Thread(target=mp3, args=(metapath3[ind3[4][0]:ind3[4][1], :], sample))\n",
    "\n",
    "t7 = threading.Thread(target=mp4, args=(metapath4[ind4[0][0]:ind4[0][1], :], sample))\n",
    "t8 = threading.Thread(target=mp4, args=(metapath4[ind4[1][0]:ind4[1][1], :], sample))\n",
    "t9 = threading.Thread(target=mp4, args=(metapath4[ind4[2][0]:ind4[2][1], :], sample))\n",
    "t10 = threading.Thread(target=mp4, args=(metapath4[ind4[3][0]:ind4[3][1], :], sample))\n",
    "t11 = threading.Thread(target=mp4, args=(metapath4[ind4[4][0]:ind4[4][1], :], sample))\n",
    "t12 = threading.Thread(target=mp4, args=(metapath4[ind4[5][0]:ind4[5][1], :], sample))\n",
    "t13 = threading.Thread(target=mp4, args=(metapath4[ind4[6][0]:ind4[6][1], :], sample))\n",
    "t14 = threading.Thread(target=mp4, args=(metapath4[ind4[7][0]:ind4[7][1], :], sample))\n",
    "t15 = threading.Thread(target=mp4, args=(metapath4[ind4[8][0]:ind4[8][1], :], sample))\n",
    "t16 = threading.Thread(target=mp4, args=(metapath4[ind4[9][0]:ind4[9][1], :], sample))\n",
    "t17 = threading.Thread(target=mp4, args=(metapath4[ind4[10][0]:ind4[10][1], :], sample))\n",
    "t18 = threading.Thread(target=mp4, args=(metapath4[ind4[11][0]:ind4[11][1], :], sample))\n",
    "t19 = threading.Thread(target=mp4, args=(metapath4[ind4[12][0]:ind4[12][1], :], sample))\n",
    "t20 = threading.Thread(target=mp4, args=(metapath4[ind4[13][0]:ind4[13][1], :], sample))\n",
    "\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()\n",
    "t5.start()\n",
    "t6.start()\n",
    "t7.start()\n",
    "t8.start()\n",
    "t9.start()\n",
    "t10.start()\n",
    "t11.start()\n",
    "t12.start()\n",
    "t13.start()\n",
    "t14.start()\n",
    "t15.start()\n",
    "t16.start()\n",
    "t17.start()\n",
    "t18.start()\n",
    "t19.start()\n",
    "t20.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "t4.join()\n",
    "t5.join()\n",
    "t6.join()\n",
    "t7.join()\n",
    "t8.join()\n",
    "t9.join()\n",
    "t10.join()\n",
    "t11.join()\n",
    "t12.join()\n",
    "t13.join()\n",
    "t14.join()\n",
    "t15.join()\n",
    "t16.join()\n",
    "t17.join()\n",
    "t18.join()\n",
    "t19.join()\n",
    "t20.join()\n",
    "\n",
    "#tip : use ctrl + left mouse click to have cursir select multiple lines and change at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn1 = sqlite3.connect(\"Features.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(features, index = [i for i in range(110001)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe.to_sql(\"FeaturesRaw\", conn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()\n",
    "conn1.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
