{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Filename     Lemma  CNG        Word  Index1  Index2\n",
      "0         1    pañcan   41   pañcan_41       0       0\n",
      "1         1     ratna   41    ratna_41       1       0\n",
      "2         1    mukhya   41   mukhya_41       2       0\n",
      "3         1        ca    2        ca_2       3       0\n",
      "4         1  uparatna    3  uparatna_3       3       1\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "this file is used to check the graph we created using sql, we create another graph with the same concpet \n",
    "but by iterating through each row. This is done on a server with lot of memory and is the bruteforce approach\n",
    "to making the graph. So we do this only for 1000 entries.\n",
    "'''\n",
    "\n",
    "conn = sqlite3.connect('Extracted.db')\n",
    "dfe = pd.read_sql(sql = 'SELECT * FROM Extracted', con = conn)\n",
    "print(dfe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [S_no, Entity_1, Type_1, Entity_2, Type_2, Weight]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#This process will be extremly slow as we are iterating through all the vales, use this code to cross check the result obtained from using sql\n",
    "\n",
    "z=0\n",
    "global z\n",
    "df = pd.DataFrame(columns = ['S_no','Entity_1', 'Type_1', 'Entity_2', 'Type_2', 'Weight'])\n",
    "global df\n",
    "#df is our graph that we want to create\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "def extraction(start, end):\n",
    "    \n",
    "    try:\n",
    "        for sentence in dfe.Filename.unique():\n",
    "            #dfe.Filename.unique() returns all the unique filenames through which we will iterate\n",
    "            \n",
    "            #if sentence%100 == 0: \n",
    "                #print(sentence, end = ' ')\n",
    "                #to show progress of execution\n",
    "\n",
    "\n",
    "            temp = pd.read_sql_query(\"SELECT Lemma, CNG, Word FROM Extracted WHERE Filename = %d\" %(sentence), conn)\n",
    "            #selecting all Lemma, CNG pairs from a scentence/file.\n",
    "\n",
    "            for i in range(len(temp.Lemma)):\n",
    "                #iterating through all the values once\n",
    "\n",
    "                for j in range(len(temp.Lemma)):\n",
    "                    #iterating through all the values for the 2nd time so that we can compare\n",
    "\n",
    "                    if i != j : #condition so that values in same row are not counted\n",
    "\n",
    "                        #lemma lemma edge\n",
    "                        values = df.query(\"Entity_1 == '%s' & Entity_2 == '%s' \" %(str(temp.Lemma[i]), str(temp.Lemma[j])))\n",
    "                        #checking if a edge exists in the graph or it needs to be created\n",
    "\n",
    "                        if values.empty : \n",
    "                            #values.empty return true if dataframe is empty\n",
    "                            #creating the edge\n",
    "                            df.loc[z] = [z, temp.Lemma[i], 'Lemma', temp.Lemma[j], 'Lemma', 1]\n",
    "                            z += 1\n",
    "\n",
    "                        else:\n",
    "                            #as the edge already exists we just increase the count\n",
    "                            df.Weight[values['S_no']] += 1\n",
    "\n",
    "\n",
    "                        #Lemma CNG Edge\n",
    "                        values = df.query(\"Entity_1 == '%s' & Entity_2 == '%s' \" %(str(temp.Lemma[i]), str(temp.CNG[j])))\n",
    "                        if values.empty :\n",
    "                            df.loc[z] = [z, temp.Lemma[i], 'Lemma', str(temp.CNG[j]), 'CNG', 1] \n",
    "                            z += 1\n",
    "\n",
    "                        else:\n",
    "                            df.Weight[values['S_no']] += 1\n",
    "\n",
    "                        #Lemma Word Edge\n",
    "\n",
    "                        values = df.query(\"Entity_1 == '%s' & Entity_2 == '%s' \" %(str(temp.Lemma[i]), str(temp.Word[j])))\n",
    "                        if values.empty :\n",
    "                            df.loc[z] = [z, temp.Lemma[i], 'Lemma', temp.Word[j], 'Word', 1]\n",
    "                            z += 1\n",
    "\n",
    "                        else:\n",
    "                            df.Weight[values['S_no']] += 1\n",
    "\n",
    "                        #CNG CNG edge\n",
    "                        values = df.query(\"Entity_1 == '%s' & Entity_2 == '%s' \" %(str(temp.CNG[i]), str(temp.CNG[j])))\n",
    "                        if values.empty :\n",
    "                            df.loc[z] = [z, str(temp.CNG[i]), 'CNG', str(temp.CNG[j]), 'CNG', 1] \n",
    "                            z += 1\n",
    "\n",
    "                        else:\n",
    "                            df.Weight[values['S_no']] += 1\n",
    "\n",
    "                        #CNG Word edge\n",
    "\n",
    "                        values = df.query(\"Entity_1 == '%s' & Entity_2 == '%s' \" %(str(temp.CNG[i]), str(temp.Word[j])))\n",
    "                        if values.empty :\n",
    "                            df.loc[z] = [z, str(temp.CNG[i]), 'CNG', temp.Word[j], 'Word', 1] \n",
    "                            z += 1\n",
    "\n",
    "                        else:\n",
    "                            df.Weight[values['S_no']] += 1\n",
    "\n",
    "                        #Word Word Edge\n",
    "\n",
    "                        values = df.query(\"Entity_1 == '%s' & Entity_2 == '%s' \" %(str(temp.Word[i]), str(temp.Word[j])))\n",
    "                        if values.empty :\n",
    "                            df.loc[z] = [z, temp.Word[i], 'Word', temp.Word[j], 'Word', 1] \n",
    "                            z += 1\n",
    "\n",
    "                        else:\n",
    "                            df.Weight[values['S_no']] += 1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    print(df.head())\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"DROP TABLE IF EXISTS Graph\")\n",
    "    df.to_sql('Graph', conn)\n",
    "    c.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#threading the process to increase speed/ parallel processing\n",
    "#no of files = 442383\n",
    "#we will check for 1000 files, and use the sql code from GraphFinal.sql on the same 1000 files\n",
    "w = 0\n",
    "y = 1000\n",
    "itr = 1\n",
    "for x in range(itr):\n",
    "    \n",
    "    t1 = threading.Thread(target=extraction, args=(w,w+y))\n",
    "    w += y\n",
    "    t2 = threading.Thread(target=extraction, args=(w,w+y))\n",
    "    w += y\n",
    "    t3 = threading.Thread(target=extraction, args=(w,w+y))\n",
    "    w += y\n",
    "    t4 = threading.Thread(target=extraction, args=(w,w+y))\n",
    "    w += y\n",
    "    t5 = threading.Thread(target=extraction, args=(w,w+y))\n",
    "    w += y\n",
    "    t6 = threading.Thread(target=extraction, args=(w,w+y))\n",
    "    w += y\n",
    "    t7 = threading.Thread(target=extraction, args=(w,w+y))\n",
    "    w += y\n",
    "    t8 = threading.Thread(target=extraction, args=(w,w+y))\n",
    "    w += y\n",
    "    t9 = threading.Thread(target=extraction, args=(w,w+y))\n",
    "    w += y\n",
    "    t10 = threading.Thread(target=extraction, args=(w,w+y))\n",
    "    w += y\n",
    "\n",
    "                        \n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t3.start()\n",
    "    t4.start()\n",
    "    t5.start()\n",
    "    t6.start()\n",
    "    t7.start()\n",
    "    t8.start()\n",
    "    t9.start()\n",
    "    t10.start()\n",
    "\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    t3.join()\n",
    "    t4.join()\n",
    "    t5.join()\n",
    "    t6.join()\n",
    "    t7.join()\n",
    "    t8.join()\n",
    "    t9.join()\n",
    "    t10.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
